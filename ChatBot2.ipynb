{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyttsx3 in c:\\users\\shubham singh\\anaconda3\\lib\\site-packages (2.90)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\shubham singh\\anaconda3\\lib\\site-packages (from pyttsx3) (305.1)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\shubham singh\\anaconda3\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: comtypes in c:\\users\\shubham singh\\anaconda3\\lib\\site-packages (from pyttsx3) (1.1.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: SpeechRecognition in c:\\users\\shubham singh\\anaconda3\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: requests>=2.26.0 in c:\\users\\shubham singh\\anaconda3\\lib\\site-packages (from SpeechRecognition) (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shubham singh\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\shubham singh\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\shubham singh\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shubham singh\\anaconda3\\lib\\site-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install SpeechRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in c:\\users\\shubham singh\\anaconda3\\lib\\site-packages (0.2.13)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import pyttsx3\n",
    "import speech_recognition as sr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint \n",
    "checkpoint = \"microsoft/DialoGPT-medium\"\n",
    "# download and cache tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "# download and cache pre-trained model\n",
    "model = AutoModelForCausalLM.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a ChatBot class with all necessary modules to make a complete conversation\n",
    "class ChatBot():\n",
    "    # initialize\n",
    "    def __init__(self):\n",
    "        # once chat starts, the history will be stored for chat continuity\n",
    "        self.chat_history_ids = None\n",
    "        # make input ids global to use them anywhere within the object\n",
    "        self.bot_input_ids = None\n",
    "        # a flag to check whether to end the conversation\n",
    "        self.end_chat = False\n",
    "        # Initialize Text-to-Speech Engine\n",
    "        self.engine = pyttsx3.init()\n",
    "        # Initialize Speech Recognition Engine\n",
    "        self.recognizer = sr.Recognizer()\n",
    "        # initialize tokenizer and model\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\",padding_side=\"left\")\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
    "        # set seed for consistency\n",
    "        \n",
    "        # greet while starting\n",
    "        self.welcome()\n",
    "        self.listen()\n",
    "\n",
    "\n",
    "# Define a function to speak text\n",
    "    def speak(self,text=\"\"):\n",
    "        self.engine.say(text)\n",
    "        self.engine.runAndWait()\n",
    "    \n",
    "    def listen(self):\n",
    "        with sr.Microphone() as source:\n",
    "            audio = self.recognizer.listen(source)\n",
    "        try:\n",
    "            text = self.recognizer.recognize_google(audio)\n",
    "            self.user_input(text)\n",
    "            self.bot_response()\n",
    "        except:\n",
    "            self.bot_response(\"I'm sorry, I didn't catch that.\")\n",
    "        self.recognizer = sr.Recognizer()\n",
    "\n",
    "    def welcome(self):\n",
    "        time.sleep(2)\n",
    "        self.speak(\"Lets begin the conversation ...\")\n",
    "        # some time to get user ready\n",
    "        time.sleep(2)\n",
    "        self.speak('Say \"bye\" or \"quit\" or \"exit\" to end chat \\n')\n",
    "        # give time to read what has been printed\n",
    "        time.sleep(3)\n",
    "        # Greet and introduce\n",
    "        greeting = np.random.choice([\n",
    "            \"Welcome, I am ChatBot, here for your kind service\",\n",
    "            \"Hey, Great day! I am your virtual assistant\",\n",
    "            \"Hello, it's my pleasure meeting you\",\n",
    "        ])\n",
    "        self.speak(\"ChatBot >>  \" + greeting)\n",
    "        \n",
    "    def user_input(self, text=\"\"):\n",
    "        # end conversation if user wishes so\n",
    "        if text.lower().strip() in ['bye', 'quit', 'exit']:\n",
    "            # turn flag on \n",
    "            self.end_chat=True\n",
    "            # a closing comment\n",
    "            self.speak('ChatBot >>  See you soon! Bye!')\n",
    "            time.sleep(1)\n",
    "            self.speak('\\nQuitting ChatBot ...')\n",
    "        else:\n",
    "            # continue chat, preprocess input text\n",
    "            # encode the new user input, add the eos_token and return a tensor in Pytorch\n",
    "            self.new_user_input_ids = self.tokenizer.encode(text + self.tokenizer.eos_token, \\\n",
    "                                                       return_tensors='pt')\n",
    "            \n",
    "   \n",
    "   \n",
    "\n",
    "    def bot_response(self, text=None):\n",
    "        # check if chat should end\n",
    "        if self.end_chat:\n",
    "            return\n",
    "        \n",
    "        # append the new user input tokens to the chat history\n",
    "        # if chat has already begun\n",
    "        if self.chat_history_ids is not None:\n",
    "           self.bot_input_ids = torch.cat([self.chat_history_ids, self.new_user_input_ids], dim=-1) \n",
    "        else:\n",
    "            # if first entry, initialize bot_input_ids\n",
    "            self.bot_input_ids = self.new_user_input_ids\n",
    "            \n",
    "        # define the new chat_history_ids based on the preceding chats\n",
    "        # generated a response while limiting the total chat history to 1000 tokens, \n",
    "        self.chat_history_ids = self.model.generate(self.bot_input_ids,\n",
    "                                                    max_length=1000,\n",
    "                                                    pad_token_id=self.tokenizer.eos_token_id,\n",
    "                                                    no_repeat_ngram_size=3,\n",
    "                                                    do_sample=True,\n",
    "                                                    top_k=100,\n",
    "                                                    top_p=0.7,\n",
    "                                                    temperature=0.8)\n",
    "                                            \n",
    "    \n",
    "        # last ouput tokens from bot\n",
    "        response = self.tokenizer.decode(self.chat_history_ids[:, self.bot_input_ids.shape[-1]:][0], \\\n",
    "                               skip_special_tokens=True)\n",
    "        # in case, bot fails to answer\n",
    "        if response == \"\":\n",
    "           response = self.random_response()\n",
    "        # speak bot response\n",
    "        self.speak(\"chatbot>>\" +response)\n",
    "        \n",
    "        # If there is text to be spoken, speak it\n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n",
      "A decoder-only architecture is being used, but right-padding was detected! For correct generation results, please set `padding_side='left'` when initializing the tokenizer.\n"
     ]
    }
   ],
   "source": [
    "# build a ChatBot object\n",
    "bot = ChatBot()\n",
    "# start chatting\n",
    "while True:\n",
    "    bot.speak()\n",
    "   \n",
    "    # receive user input\n",
    "    bot.user_input()\n",
    "    # check whether to end chat\n",
    "    if bot.end_chat:\n",
    "        break\n",
    "    # output bot response\n",
    "    bot.bot_response()    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
